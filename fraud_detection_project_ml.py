# -*- coding: utf-8 -*-
"""fraud_detection_project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GsMBUKMRtpHnhYkMhTBwrXnga3-BLk3W

**Importing Libraries**
"""

import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.impute import SimpleImputer

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, precision_recall_curve, precision_score, recall_score, f1_score

"""**Uploading** **Dataset**"""

df = pd.read_csv("/content/Fraud Detection Dataset.csv")

"""First 3 rows"""

df.head(3)

df.drop(columns = ["Transaction_ID","User_ID"], inplace=True)

"""Checking shape"""

df.shape

"""Checking Data types"""

df.info()

df.describe()

"""Checking Null Values"""

df.isnull().sum()

"""Filling Null Values"""

num_cols = ["Transaction_Amount","Time_of_Transaction"]  #Filling Numerical Values

num_imputer = SimpleImputer(strategy="median")
df[num_cols] = num_imputer.fit_transform(df[num_cols])


device_imputer = SimpleImputer(strategy = "constant", fill_value="Unknown Device") #Filling Device_Used column
df[["Device_Used"]] = device_imputer.fit_transform(df[["Device_Used"]])

cat_cols = ["Location","Payment_Method"]   #Filling Categoricl Values

cat_imputer = SimpleImputer(strategy = "constant", fill_value="Unknown")
df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])

"""Checking whether the Values are Filled or Not"""

df.isnull().sum()

#Create a binary feature to capture higher fraud risk during night-time transactions.

df["Is_Night"] = df["Time_of_Transaction"].apply(
                                  lambda x: 1
                                  if x >= 22 or x <= 5
                                  else 0
                                  )

"""Checking columns names"""

df.columns

"""Fraud vs Non-Fraud Transactions"""

plt.figure(figsize=(5,3))
sns.countplot(x='Fraudulent',hue = "Fraudulent", data=df)
plt.title("Fraud vs Non-Fraud Transactions")
plt.show()
print()
print("Dataset is highly Imbalanced, hence recall optimization is required.")

sns.countplot(x = "Is_Night", hue = "Fraudulent", data = df)
plt.title("Fraud Distribution : Day vs Night")
plt.ylabel("no. of frauds")
plt.show()
print()
print("Fraud transactions are significantly higher during night hours compared to daytime.")

"""Encoding"""

enc_cat_cols = pd.get_dummies(df[["Transaction_Type","Device_Used","Location","Payment_Method"]], drop_first= True)
num_cols = df[["Transaction_Amount","Time_of_Transaction","Previous_Fraudulent_Transactions","Account_Age",
               "Number_of_Transactions_Last_24H","Is_Night"]]

"""Input/Output"""

x = pd.concat([enc_cat_cols, num_cols], axis = 1)
y = df["Fraudulent"]

"""Train-Test_split and Scaling"""

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, stratify=y, random_state=42)

std_scaler = StandardScaler()
x_train_scaled = std_scaler.fit_transform(x_train)
x_test_scaled = std_scaler.transform(x_test)

"""Logistic Regression"""

lr = LogisticRegression(class_weight="balanced")
lr.fit(x_train_scaled, y_train)

"""Checking Accuracy"""

y_pred = lr.predict(x_test_scaled)
accuracy_score(y_test, y_pred)*100

"""Confusion matrix"""

print("Confusion Matrix : ", confusion_matrix(y_test, y_pred))
print()

plt.figure(figsize = (4,3))
sns.heatmap(confusion_matrix(y_test, y_pred), annot = True, fmt='d')
plt.xlabel("Predicted Values")
plt.ylabel("Actual Values")
plt.title("Confusion Matrix")
plt.show()

"""Precision, Recall, f1-score"""

print("Precision Score : ",precision_score(y_test, y_pred)*100)
print("Recall Score : ",recall_score(y_test, y_pred)*100)
print("F1-score : ", f1_score(y_test, y_pred)*100)

"""Threshold tuning"""

y_prob = lr.predict_proba(x_test_scaled)[:,1]
y_pred_th = (y_prob > 0.4149).astype(int)

"""confusion matrix, precision, recall, f1-score after threshold tuning"""

print("Precision Score : ",precision_score(y_test, y_pred_th)*100)
print("Recall Score : ",recall_score(y_test, y_pred_th)*100)
print("F1-score : ", f1_score(y_test, y_pred_th)*100)


print("Confusion Matrix : ", confusion_matrix(y_test, y_pred_th))
print()

plt.figure(figsize = (4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_th), annot = True, fmt='d')
plt.xlabel("Predicted Values")
plt.ylabel("Actual Values")
plt.title("Confusion Matrix")
plt.show()

"""Precision-Recall-Curve"""

precision, recall, thresholds = precision_recall_curve(y_test, y_prob)
plt.plot(recall, precision)
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precisionâ€“Recall-Curve")
plt.show()
print()
print("Threshold tuning helps balance recall and precision.")

"""# Taking User Input for Fraud Prediction

"""

Transaction_Amount = int(input("Enter Transaction_Amount : "))
Transaction_Type = input("Enter Transaction_Type (ATM/UPI/POS) : ")
Time_of_Transaction = int(input("Enter Time_of_Transaction in hour(0-23) : "))

Device_Used = input("Enter Device_Used ('Tablet', 'Mobile', 'Desktop', 'Unknown Device') : ")
Location = input("Enter Location ('San Francisco', 'New York', 'Unknown', 'Chicago', 'Boston','Houston', 'Miami', 'Los Angeles', 'Seattle') : ")

Previous_Fraudulent_Transactions = int(input("Enter Previous_Fraudulent_Transactions : "))
Account_Age = int(input("Enter Account_Age : "))
Number_of_Transactions_Last_24H = int(input("Enter Number_of_Transactions_Last_24H : "))

Payment_Method = input("Enter Payment_Method : ")
Is_Night = int(input("Enter Is_Night(0/1) : "))

#Converting into DataFrame
new_data = {
    "Transaction_Amount" : Transaction_Amount,
    "Transaction_Type"   : Transaction_Type,
    "Time_of_Transaction": Time_of_Transaction,
    "Device_Used"        : Device_Used,
    "Location"           : Location,
    "Previous_Fraudulent_Transactions" : Previous_Fraudulent_Transactions,
    "Account_Age"        : Account_Age,
    "Number_of_Transactions_Last_24H"  : Number_of_Transactions_Last_24H,
    "Payment_Method"     : Payment_Method,
    "Is_Night"           : Is_Night
}
new_df = pd.DataFrame([new_data])

#Encoding
new_df_encoded = pd.get_dummies(new_df[["Transaction_Type","Device_Used","Location","Payment_Method"]], drop_first = True)

num_cols = new_df[["Transaction_Amount","Time_of_Transaction","Previous_Fraudulent_Transactions","Account_Age",
               "Number_of_Transactions_Last_24H","Is_Night"]]
new_final = pd.concat([num_cols, new_df_encoded], axis=1)
new_final = new_final.reindex(columns=x.columns, fill_value=0)

#Scaling
new_df_scaled = std_scaler.transform(new_final)

# Predict with threshold
fraud_prob = lr.predict_proba(new_df_scaled)[:, 1]
prediction = 1 if fraud_prob >= 0.4149 else 0

print("Fraud Probability:",fraud_prob[0]*100)

if prediction == 1:
    print("Fraud Transaction!")
else:
    print("Normal Transaction")

print("""
                    ======= PROJECT SUMMARY =======

Built an end-to-end Fraud Detection System using Logistic Regression.

Performed data preprocessing including missing value imputation and feature engineering.

Identified strong class imbalance in fraud transactions and optimized model for recall.

Created a time-based feature (Is_Night) to capture higher fraud risk during night hours.

Applied one-hot encoding for categorical variables and StandardScaler for feature scaling.

Handled imbalanced data using class_weight='balanced' in Logistic Regression.

Used stratified train-test split to maintain fraud distribution.

Performed threshold tuning (0.4149) instead of default 0.5 to improve fraud recall.

Evaluated model using Accuracy, Confusion Matrix, Precision, Recall, F1-score,
and Precision-Recall Curve.

Achieved high fraud detection recall while maintaining balanced precision.

Developed a real-time transaction prediction pipeline with fraud probability output.
""")